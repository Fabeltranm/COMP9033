{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 05: Data modelling and model selection\n",
    "## Introduction\n",
    "\n",
    "This week's lab is focused on data modelling and model selection. At the end of the lab, you should be able to use `scikit-learn` to:\n",
    "\n",
    "- Create a rule-based spam classification model for SMS messages.\n",
    "- Predict whether a given SMS message is spam or not.\n",
    "- Generate a set of different candidate models and select the best one.\n",
    "- Measure the accuracy of the final model.\n",
    "\n",
    "### Getting started\n",
    "\n",
    "Let's start by importing the packages we'll need. Like last week, we're going to use `scikit-learn` (`sklearn`), a modelling and machine learning library for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_predict\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the data. Write the path to your sms.csv file in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = 'data/sms.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to load the CSV data into a pandas data frame with the columns `label` and `message`.\n",
    "\n",
    "> **Note:** This week, the CSV file is not comma separated, but instead tab separated. We can tell `pandas` about the different format using the `sep` argument, as shown in the cell below. For more information, see the `read_csv` [documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sms = pd.read_csv(data_file, sep='\\t', header=None, names=['label', 'message'])\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a spam classifier\n",
    "\n",
    "Let's build a rule-based model that classifies the SMS messages as either *spam* or *ham* by matching the content of the message against a known list of spam phrases. The cell below defines a custom `scitkit-learn` classifier that accepts an optional list of spam phrases to match against (the `spam` argument) and a optional boolean (the `lowercase` argument) that defines whether the messages should be converted to lowercase before comparison with the phrases in the list.\n",
    "\n",
    "> **Note:** `scikit-learn` doesn't support generic rule-based models out of the box, so we have to code our own. However, it does support many different kinds of machine learning models, so we won't usually have to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PhraseClassifier(BaseEstimator, ClassifierMixin):\n",
    "    '''A rule-based spam classifer, backed by a list of spam phrases.'''\n",
    "\n",
    "    def __init__(self, spam=[], lowercase=False):\n",
    "        '''Initialises the classifier.\n",
    "        \n",
    "        Args:\n",
    "            spam: A list of phrases used to identify spam.\n",
    "            lowercase: Whether to convert messages to lowercase before predicting their class.\n",
    "        '''\n",
    "        self.spam = spam\n",
    "        self.lowercase = lowercase\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        '''Fits the classifier.\n",
    "        \n",
    "        Note: As the classifier is rule-based, this is just a dummy method to ensure\n",
    "        compatability with scikit-learn.\n",
    "        \n",
    "        Args:\n",
    "            X: Unused.\n",
    "            y: Unused.\n",
    "        \n",
    "        Returns:\n",
    "            The classifier object (self).\n",
    "        '''\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        '''Predicts the classes of the given messages.\n",
    "        \n",
    "        Args:\n",
    "            X: List of messages to classify.\n",
    "            y: Unused.\n",
    "        \n",
    "        Returns:\n",
    "            A list of classifications, corresponding to the given messages.\n",
    "        '''\n",
    "        results = []\n",
    "        for message in X:\n",
    "            message = message.lower() if self.lowercase else message\n",
    "            cls = self.spam_or_ham(message)\n",
    "            results.append(cls)\n",
    "        return results\n",
    "\n",
    "    def spam_or_ham(self, message):\n",
    "        '''Classifies the given message as spam or ham.\n",
    "        \n",
    "        Args:\n",
    "            message: The message to classify.\n",
    "        \n",
    "        Returns:\n",
    "            The predicted class of the message: 'spam' or 'ham'.\n",
    "        '''\n",
    "        # Start out assuming we have ham\n",
    "        result = 'ham'\n",
    "        \n",
    "        # If any of the phrases in self.spam match, then mark the message as spam\n",
    "        for phrase in self.spam:\n",
    "            if phrase in message:\n",
    "                result = 'spam'\n",
    "                break\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def score(self, X, y=None):\n",
    "        '''Computes a score for the given messages and ground truth labels.\n",
    "                \n",
    "        Args:\n",
    "            X: List of messages to classify.\n",
    "            y: List of the true classes of the messages.\n",
    "        \n",
    "        Returns:\n",
    "            The average number of correct classifications by the model.\n",
    "        '''\n",
    "        y_pred = self.predict(X, y)\n",
    "        return sum([1 if y1 == y2 else 0 for y1, y2 in zip(y, y_pred)]) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By convention, when we build a predictive model using `scikit-learn`, we separate our data into two variables, `X` and `y`:\n",
    "\n",
    "- `X`: This represents the data to train on or evaluate, i.e. it is a matrix consisting of explanatory variables / features.\n",
    "- `y`: This represents the true values of the quantity we are trying to predict, i.e. it is the target.\n",
    "\n",
    "For instance, if we wanted to predict ice cream sales based on temperature, then we would assign the temperature data (an explanatory variable) to the `X` variable and the ice cream sales data (the target variable) to the `y` variable.\n",
    "\n",
    "As we are trying to predict the label (spam or ham) of SMS messages based on their content, we'll assign the messages (the explanatory variables) to the `X` variable and the labels (the target variables) to the `y` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = sms['message']\n",
    "y = sms['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build our first classifier. Let's create one that marks every message as ham to start with (i.e. one with no spam phrases). It won't be very useful, but it will give us a baseline accuracy from which to improve on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = PhraseClassifier()  # clf is short for classifier\n",
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure how well our classifier works, let's create a classification report using the true labels for the SMS messages (`y`) and the predicted labels we've just created (`y_pred`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we haven't covered some of the terms here in class yet, they're not difficult to understand:\n",
    "\n",
    "- **Precision:** The proportion of the classifications that were correct (e.g. correctly predicted hams / total predicted hams). Ideally, precision is 100%.\n",
    "- **Recall:** The proportion of a class that was correctly predicted (e.g. correctly predicted hams / total actual hams). Ideally, recall is 100%.\n",
    "- **F1 score:** The harmonic mean of precision and recall. This acts as a \"unified\" measure of accuracy. Ideally, the F1 score is 100%.\n",
    "- **Support:** The number of samples of the given class (e.g. the numbers of hams and spams).\n",
    "\n",
    "We can interpret the results above like this:\n",
    "\n",
    "- 87% of the messages we labelled as ham were actually ham (precision for ham = 0.87).\n",
    "- None of the messages we labelled as spam were actually spam (precision for spam = 0.00).\n",
    "- We labelled every actual ham as ham (recall for ham = 1.00).\n",
    "- We labelled no actual spam as spam (recall for spam = 0.00).\n",
    "- We made predictions for 5572 messages, 4825 of which were ham and 747 of which were spam.\n",
    "\n",
    "This isn't surprising, given that our classifier labels every message as ham and ~87% of our dataset (4825/5572) is ham.\n",
    "\n",
    "Let's make an improvement by adding the spam phrases \"urgent\" and \"win\". This is easy to do: we just have to create a new classifier and use it to make some new predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = PhraseClassifier(spam=['urgent', 'win'])\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the results have improved:\n",
    "\n",
    "- 88% of the messages we labelled as ham were actually ham (precision for ham = 0.88).\n",
    "- 51% of the messages we labelled as spam were actually spam (precision for spam = 0.51).\n",
    "- We labelled 99% of actual ham as ham (recall for ham = 0.99).\n",
    "- We labelled 9% of actual spam as spam (recall for spam = 0.09).\n",
    "\n",
    "Our overall F1 score has also increased (from 0.80 to 0.82), which indicates that our model is performing better in general.\n",
    "\n",
    "The `PhraseClassifier` algorithm also accepts a boolean `lowercase` keyword argument. When it's set to true, messages are converted to lowercase before being compared with our list of spam phrases. This way, we can catch messages like \"WINNER!! ...\" as well as \"SIX chances to win...\". Let's see what effect this has on our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = PhraseClassifier(spam=['urgent', 'win'], lowercase=True)\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this has improved our spam detector!\n",
    "\n",
    "## Model selection\n",
    "\n",
    "So far, we've chosen phrases that are good indicators of spam. But if we include a word that isn't such a good indicator, our model becomes worse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = PhraseClassifier(spam=['urgent', 'win', 'hi'], lowercase=True)\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice if we choose a set of spam keywords that *maximized* the performance of our model. We can do this using model selection, i.e. building a set of different candidate models and choosing the best one. This is easy to do with `scikit-learn`!\n",
    "\n",
    "Let's start by creating a sorted list of the most popular words in the spam messages in our training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of the words in the training set messages that are labelled as spam\n",
    "spam_messages = X[y == 'spam']\n",
    "spam_words = [word.lower() for message in spam_messages for word in message.split()]\n",
    "\n",
    "# Order the spam words by popularity\n",
    "top_spam_words = pd.Series(spam_words).value_counts().index.tolist()\n",
    "\n",
    "# Print the top ten\n",
    "top_spam_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a lot of the most popular words are ones we commonly use. These aren't good indicators of spam in general, so let's remove them. `scikit-learn` defines a set of *stop words*, i.e. words that are so commonly used that they don't indicate anything in particular. Let's remove these from our set of most popular words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_spam_words = [word for word in top_spam_words if word not in stop_words.ENGLISH_STOP_WORDS]\n",
    "\n",
    "top_spam_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a better set of words to use. Let's make a list of all the possible different combinations of the most popular of these words (a brute force approach) using Python's [`itertools.combinations`](https://docs.python.org/2/library/itertools.html#itertools.combinations) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "candidates = top_spam_words[:5]  # Use the top five words\n",
    "combinations = [combination for n in range(1, len(candidates)) \\\n",
    "                for combination in itertools.combinations(candidates, n)]\n",
    "\n",
    "print('Total combinations: %d' % len(combinations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define a set of parameters to build models for. The set is just a Python dictionary, where the keys match the arguments of the classifier we're using (i.e. `PhraseClassifier`) and the values represent different choices that can be made for a particular key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'spam': combinations,       # Try every combination of spam phrases\n",
    "    'lowercase': [True, False]  # Try setting lowercase True and False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) class from `scikit-learn` to build every possible model defined by the parameters and choose the best one (i.e. to do model selection). Generally, when we use `GridSearchCV`, we will specify three parameters:\n",
    "\n",
    "1. A model-building algorithm.\n",
    "2. The set of parameters to use to build models.\n",
    "3. An internal cross validation technique to use to measure the accuracy of the models built using the parameters.\n",
    "\n",
    "In this case, we will use `PhraseClassifier` to build the model and the set of parameters above to generate the different configurations.\n",
    "\n",
    "We can set the cross validation technique that the grid search uses via the `cv` keyword argument. As we're trying to predict a categorical variable (spam or ham), and our class sizes are imbalanced (87% of the data is ham), we should make sure to stratify the selection of train and test sets to ensure similar class distributions in each. One way we can do this is with the [`StratifiedKFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) class, which implements a stratified version of K-fold cross validation.\n",
    "\n",
    "We can also use an outer cross validation to evaluate the error of the model selected by the grid search. For this, we need to create a second cross validator object and use it to make a set of final predictions, which we can compare to the ground truth labels to compute our overall model accuracy.\n",
    "\n",
    "> **Note:** In the cell below, we also set `random_state=0` so that the split occurs the same way each time. This is just so this notebook runs the same way on different computers and everyone gets the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use inner CV to select the best model\n",
    "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)  # K = 5\n",
    "\n",
    "clf = GridSearchCV(PhraseClassifier(), param_grid=param_grid, cv=inner_cv)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Use outer CV to evaluate the error of the best model\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)  # K = 10, doesn't have to be the same\n",
    "y_pred = cross_val_predict(clf, X, y, cv=outer_cv)\n",
    "\n",
    "print(classification_report(y, y_pred))\n",
    "print('Best parameters: %s' % clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the *best* spam classifier that can be generated from the top ten spam words is the one that simply checks whether a messages contains the word \"free\" or not. If we had enough resources (time, compute power), we could determine the best spam classifier based on *all* of the words in the spam messages, not just the top five."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
