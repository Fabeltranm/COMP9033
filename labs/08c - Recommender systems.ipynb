{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 08c: Recommender systems\n",
    "## Introduction\n",
    "\n",
    "In this lab, you will build a simple movie recommender using $k$ nearest neighbours regression. At the end of the lab, you should be able to:\n",
    "\n",
    "- Replace missing values in a data set.\n",
    "- Create a $k$ nearest neighbours regression model.\n",
    "- Use the model to predict new values.\n",
    "- Measure the accuracy of the model.\n",
    "\n",
    "### Getting started\n",
    "\n",
    "Let's start by importing the packages we'll need. This week, we're going to use the `neighbors` subpackage from `scikit-learn` to build $k$ nearest neighbours models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_predict\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the data. Write the path to your `ml-100k.csv` file in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'data/ml-100k.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to load the CSV data into a pandas data frame indexed by the `user_id` field in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path, index_col='user_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "\n",
    "Let's start by computing some summary statistics about the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = df.describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the data consists of film ratings in the range [1, 5] for 1664 films. Some films have been rated by many users, but the vast majority have been rated by only a few (i.e. there are many missing values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = stats.loc['count'].hist(bins=30)\n",
    "ax.set(\n",
    "    xlabel='Number of ratings',\n",
    "    ylabel='Frequency'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to replace the missing values with appropriate substitutions before we can build our model. One way to do this is to replace each instance where a user didn't see a film with the average rating of that film (although, there are others, e.g. the median or mode values). We can compute the average rating of each film via the `mean` method of the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_ratings = df.mean()\n",
    "\n",
    "average_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's substitute these values everywhere there is a missing value. With `pandas`, you can do this with the [`fillna`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html) method, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna(value=average_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data modelling\n",
    "\n",
    "Let's build a movie recommender using user-based collaborative filtering. For this, we'll need to build a model that can identify the most similar users to a given user and use that relationship to predict ratings for new movies. We can use $k$ nearest neighbours regression for this.\n",
    "\n",
    "Before we build the model, let's specify ratings for some of the films in the data set. This gives us a target variable to fit our model to. The values below are just examples - feel free to add your own ratings or change the films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = pd.Series({\n",
    "    'L.A. Confidential (1997)': 3.5,\n",
    "    'Jaws (1975)': 3.5,\n",
    "    'Evil Dead II (1987)': 4.5,\n",
    "    'Fargo (1996)': 5.0,\n",
    "    'Naked Gun 33 1/3: The Final Insult (1994)': 2.5,\n",
    "    'Wings of Desire (1987)': 5.0,\n",
    "    'North by Northwest (1959)': 5.0,\n",
    "    \"Monty Python's Life of Brian (1979)\": 4.5,\n",
    "    'Raiders of the Lost Ark (1981)': 4.0,\n",
    "    'Annie Hall (1977)': 5.0,\n",
    "    'True Lies (1994)': 3.0,\n",
    "    'GoldenEye (1995)': 2.0,\n",
    "    'Good, The Bad and The Ugly, The (1966)': 4.0,\n",
    "    'Empire Strikes Back, The (1980)': 4.0,\n",
    "    'Godfather, The (1972)': 4.5,\n",
    "    'Waterworld (1995)': 1.0,\n",
    "    'Blade Runner (1982)': 4.0,\n",
    "    'Seven (Se7en) (1995)': 3.5,\n",
    "    'Alien (1979)': 4.0,\n",
    "    'Free Willy (1993)': 1.0\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's select the features to learn from. In user-based collaborative filtering, we need to identify the users that are most similar to us. Consequently, we need to transpose our data matrix (with the `T` attribute of the data frame) so that its columns (i.e. features) represent users and its rows (i.e. samples) represent films. We'll also need to select just the films that we specified above, as our target variable consists of these only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.T.loc[y.index]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a $k$ nearest neighbours regression model to see what improvement can be made over the dummy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algorithm = KNeighborsRegressor()\n",
    "\n",
    "parameters = {\n",
    "    'n_neighbors': [2, 5, 10, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['manhattan', 'euclidean']\n",
    "}\n",
    "\n",
    "# Use inner CV to select the best model\n",
    "inner_cv = KFold(n_splits=10, shuffle=True, random_state=0)  # K = 10\n",
    "\n",
    "clf = GridSearchCV(algorithm, parameters, cv=inner_cv, n_jobs=-1)  # n_jobs=-1 uses all available CPUs = faster\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Use outer CV to evaluate the error of the best model\n",
    "outer_cv = KFold(n_splits=10, shuffle=True, random_state=0)  # K = 10, doesn't have to be the same\n",
    "y_pred = cross_val_predict(clf, X, y, cv=outer_cv)\n",
    "\n",
    "# Print the results \n",
    "print('Mean absolute error: %f' % mean_absolute_error(y, y_pred))\n",
    "print('Standard deviation of the error: %f' % (y - y_pred).std())\n",
    "\n",
    "ax = (y - y_pred).hist()\n",
    "ax.set(\n",
    "    title='Distribution of errors for the nearest neighbours regression model',\n",
    "    xlabel='Error'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the $k$ nearest neighbours model is able to predict ratings to within Â±0.88, with a standard deviation of 0.97. While this error is not small, it's not so large that it won't be useful. Further impovements can be made by filling the missing values in a different way or providing more ratings.\n",
    "\n",
    "### Making predictions\n",
    "\n",
    "Now that we have a final model, we can make recommendations about films we haven't rated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pd.Series()\n",
    "for film in df.columns:\n",
    "    if film in y.index:\n",
    "        continue  # If we've already rated the film, skip it\n",
    "    predictions[film] = clf.predict(df.loc[:, [film]].T)[0]\n",
    "\n",
    "predictions.sort_values(ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
